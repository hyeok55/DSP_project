{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from models import DLinear, NLinear, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 데이터 로드\n",
    "\n",
    "이 코드는 **모델 학습 전에 데이터의 스케일(척도)을 표준화하여 모델의 학습 안정성과 성능을 향상**시키기 위함. 특히, 시계열 데이터의 훈련 세트와 테스트 세트를 각각 스케일링하는 과정임.\n",
    "\n",
    "  * **스케일러 객체 생성:** `scaler = MinMaxScaler()`를 사용하여 **`MinMaxScaler` 객체**를 생성함. `MinMaxScaler`는 데이터를 **0과 1 사이**의 값으로 정규화하는 방식임.\n",
    "  * **훈련 데이터 스케일링 (Fit & Transform):** `train_data_scaled = scaler.fit_transform(train_data)`를 수행함.\n",
    "      * **`fit()`:** 훈련 데이터(`train_data`)의 최소값(Min)과 최대값(Max)을 계산하여 스케일러가 이 정보를 학습하게 함.\n",
    "      * **`transform()`:** 학습된 Min/Max 정보를 사용하여 훈련 데이터를 0과 1 사이로 변환함.\n",
    "  * **테스트 데이터 스케일링 (Transform Only):** `test_data_scaled = scaler.transform(test_data)`를 수행함.\n",
    "      * **`transform()`:** 훈련 데이터에서 학습한 Min/Max 값을 그대로 사용하여 테스트 데이터(`test_data`)를 변환함. 이는 데이터 누수(Data Leakage)를 방지하고 실제 환경과 동일하게 **훈련된 기준으로만** 새로운 데이터를 처리하도록 하기 위함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('품질전처리후데이터.csv', index_col=0)\n",
    "raw_data = raw_data.set_index('TAG_MIN')\n",
    "raw_data.index = pd.to_datetime(raw_data.index)\n",
    "raw_data = raw_data.resample('10S').mean()\n",
    "raw_data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분할: 학습-검증-테스트\n",
    "\n",
    "이 코드는 **특정 배정번호 데이터를 분리**한 후, 나머지 데이터를 **배정번호 기준**으로 **훈련(Train), 검증(Validation), 테스트(Test)** 데이터셋으로 **순차적으로 분할**함. 이는 시계열 데이터가 아닌, 배정번호(Batch ID)를 기준으로 데이터를 분리하는 독특한 방식임.\n",
    "\n",
    "  * **특정 데이터 분리:**\n",
    "\n",
    "      * `data = raw_data[raw_data['배정번호']!=148069]`를 통해 **마지막 배정번호**로 추정되는 `148069`번을 제외한 모든 데이터를 `data`에 할당함.\n",
    "      * `data_for_sim = raw_data[raw_data['배정번호']==148069]`를 통해 **`148069`번 데이터**를 따로 `data_for_sim`에 저장함. 이는 아마도 모델 학습/평가와 별개로 **시뮬레이션(Simulation)** 등을 위해 해당 배치를 별도로 활용하기 위함임.\n",
    "\n",
    "  * **훈련, 검증, 테스트 분할 (배정번호 기준):**\n",
    "\n",
    "      * **분할 기준점 설정:** 데이터의 길이 비율(70%, 80%)을 사용하여 해당 위치의 **배정번호 값**을 추출함.\n",
    "          * `data.iloc[int(len(data)*0.7), 0]` : 전체 `data`의 **70% 지점**에 있는 행의 **첫 번째 컬럼 (배정번호)** 값을 분할 기준으로 사용함.\n",
    "          * `data.iloc[int(len(data)*0.8), 0]` : 전체 `data`의 **80% 지점**에 있는 행의 **첫 번째 컬럼 (배정번호)** 값을 분할 기준으로 사용함.\n",
    "      * **`train_data` (훈련 데이터):** `data`에서 **70% 지점의 배정번호보다 작은** 모든 데이터를 훈련 세트로 사용함.\n",
    "      * **`vali_data` (검증 데이터):** `data`에서 **70% 지점의 배정번호**와 **80% 지점의 배정번호 사이**에 있는 데이터를 검증 세트로 사용함.\n",
    "      * **`test_data` (테스트 데이터):** `data`에서 **80% 지점의 배정번호보다 크거나 같은** 모든 데이터를 테스트 세트로 사용함.\n",
    "\n",
    "  * **목적:** 데이터의 **시간 순서** 대신 **생산 배치(배정번호)** 순서를 기준으로 데이터를 분할하여, 모델이 과거 배치들을 학습하고 새로운 배치들을 검증 및 테스트하도록 함. 이는 시계열 데이터가 배치 단위로 독립적인 특성을 가질 때 유용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204088, 31782, 61333)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 배정번호 제외\n",
    "data = raw_data[raw_data['배정번호']!=148069]\n",
    "data_for_sim = raw_data[raw_data['배정번호']==148069]\n",
    "\n",
    "train_data = data[data['배정번호']<data.iloc[int(len(data)*0.7),0]]\n",
    "vali_data = data[(data['배정번호']>=data.iloc[int(len(data)*0.7),0]) & (data['배정번호']<data.iloc[int(len(data)*0.8),0])]\n",
    "test_data = data[data['배정번호']>=data.iloc[int(len(data)*0.8),0]]\n",
    "\n",
    "len(train_data), len(vali_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 정규화: StandardScaling 및 Scaler 저장\n\n이 코드는 **Scikit-learn의 `StandardScaler`를 사용하여 훈련, 검증, 테스트 데이터의 특정 컬럼들을 표준화**하여 모델 학습에 적합하게 스케일링하는 과정임.\n\n  * **StandardScaler 사용:** `StandardScaler()`를 사용하여 스케일러 객체를 생성함. 이 스케일러는 데이터를 **평균이 0, 표준편차가 1**이 되도록 표준화함.\n  * **특정 컬럼만 스케일링:** 모든 데이터에 대해 `.iloc[:, 1:]` 인덱싱을 사용함. 이는 첫 번째 컬럼(인덱스 0)을 제외한 **나머지 모든 컬럼**을 스케일링 대상으로 지정함을 의미함. (일반적으로 첫 번째 컬럼은 스케일링이 필요 없는 `배정번호`와 같은 식별자 데이터일 수 있음).\n  * **훈련 데이터 학습 및 변환:** `train_data_scaled = scaler.fit_transform(train_data.iloc[:, 1:])`를 통해 훈련 데이터의 **평균과 표준편차를 학습**(`fit`)하고 이를 기준으로 데이터를 표준화(`transform`)함.\n  * **검증/테스트 데이터 변환:** `scaler.transform()`만 사용하여 검증(`vali_data`) 및 테스트(`test_data`) 데이터를 변환함. 이는 훈련 데이터에서 학습된 통계 정보(평균, 표준편차)를 사용하여 새로운 데이터들을 처리함으로써, **데이터 누수(Data Leakage)를 방지**함.\n  * **원래 데이터에 적용:** 마지막 세 줄을 통해 스케일링된 값(`*_data_scaled`)을 원래의 데이터프레임(`*_data`)의 해당 컬럼(`iloc[:, 1:]`)에 **대입하여 업데이트**함.\n  * **Scaler 저장:** `pickle`을 사용하여 학습된 scaler 객체를 `scaler.pkl` 파일로 저장함. 이는 **dashboard에서 예측 결과를 역정규화**하기 위해 필요함."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard scaling\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\n\nscaler = StandardScaler()\ntrain_data_scaled = scaler.fit_transform(train_data.iloc[:,1:])\nvali_data_scaled = scaler.transform(vali_data.iloc[:,1:])\ntest_data_scaled = scaler.transform(test_data.iloc[:,1:])\n\ntrain_data.iloc[:,1:] = train_data_scaled\nvali_data.iloc[:,1:] = vali_data_scaled\ntest_data.iloc[:,1:] = test_data_scaled\n\n# Scaler 저장 (dashboard에서 역정규화에 사용)\nwith open('scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\n\nprint(f\"StandardScaler 저장 완료: scaler.pkl\")\nprint(f\"  - 평균(mean): {scaler.mean_[:5]} (처음 5개)\")\nprint(f\"  - 표준편차(scale): {scaler.scale_[:5]} (처음 5개)\")\nprint(f\"  - 총 특성 수: {len(scaler.mean_)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터셋 정의\n",
    "\n",
    "이 코드는 **시계열 예측 모델 학습을 위해 Pandas DataFrame 형태의 시계열 데이터를 PyTorch의 `Dataset` 객체로 변환**함. 이를 통해 데이터를 효율적으로 관리하고, **슬라이딩 윈도우(Sliding Window)** 방식을 적용하여 모델 입력에 필요한 시퀀스 형태로 데이터를 공급할 수 있게 됨.\n",
    "\n",
    "  * **PyTorch `Dataset` 상속:** `torch.utils.data.Dataset` 클래스를 상속받아 시계열 데이터 전용 데이터 로딩 클래스를 정의함. 이는 PyTorch의 `DataLoader`와 함께 사용되어 데이터 미니배치(mini-batch)를 효율적으로 생성할 수 있게 함.\n",
    "  * **시계열 시퀀스 정의 (`__init__`):**\n",
    "      * `input_len`과 `output_len`을 받아 과거 `input_len` 길이의 데이터를 입력(`X`)으로, 미래 `output_len` 길이의 데이터를 예측 대상(`y`)으로 정의함.\n",
    "      * **`task`** 인수를 통해 **다변량(multivariate)** 또는 **단변량(univariate)** 예측 문제를 선택함.\n",
    "          * `multivariate`: 예측 대상(`target_name`)을 제외한 모든 컬럼을 피처(`features`)로 사용함.\n",
    "          * `univariate`: 예측 대상 컬럼만 피처로 사용함.\n",
    "  * **데이터 길이 계산 (`__len__`):**\n",
    "      * `self.max_index`를 계산하여 유효한 슬라이딩 윈도우의 최대 개수를 정의함. 이 길이를 반환하여 `DataLoader`가 반복 횟수를 알 수 있게 함.\n",
    "  * **슬라이딩 윈도우 구현 (`__getitem__`):**\n",
    "      * `idx` (인덱스)가 주어지면, 해당 인덱스부터 `input_len` 길이만큼의 피처 데이터(`X`)를 잘라냄.\n",
    "      * `input_len` 다음 위치부터 `output_len` 길이만큼의 타겟 데이터(`y`)를 잘라냄.\n",
    "      * 잘라낸 NumPy 배열 데이터를 PyTorch **`torch.tensor`** 객체로 변환하여 반환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, input_len, output_len, target_name, task=\"multivariate\"):\n",
    "        \"\"\"\n",
    "        시계열 데이터프레임을 torch Dataset으로 변환\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): 시계열 데이터 (정렬되어 있어야 함)\n",
    "            input_len (int): 입력 시퀀스 길이\n",
    "            output_len (int): 출력(예측) 시퀀스 길이\n",
    "            target_name (str): 예측 대상 컬럼명\n",
    "            task (str): 'multivariate' 또는 'univariate'\n",
    "                        - 'multivariate': 전체 feature 사용\n",
    "                        - 'univariate': target feature만 입력으로 사용\n",
    "        \"\"\"\n",
    "        assert isinstance(df, pd.DataFrame), \"df는 pandas DataFrame이어야 합니다.\"\n",
    "        assert target_name in df.columns, f\"{target_name} 컬럼이 DataFrame에 없습니다.\"\n",
    "        assert task in [\"multivariate\", \"univariate\"], \"task는 'multivariate' 또는 'univariate' 중 하나여야 합니다.\"\n",
    "\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.target_name = target_name\n",
    "        self.task = task\n",
    "\n",
    "        # feature 선택 로직\n",
    "        if task == \"multivariate\":\n",
    "            self.feature_cols = [c for c in df.columns if c != target_name]\n",
    "        else:  # univariate\n",
    "            self.feature_cols = [target_name]\n",
    "\n",
    "        self.features = df[self.feature_cols].values.astype(np.float32)\n",
    "        self.target = df[target_name].values.astype(np.float32)\n",
    "\n",
    "        self.max_index = len(df) - input_len - output_len + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(0, self.max_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        슬라이딩 윈도우 기반으로 (X, y) 반환\n",
    "        X: (input_len, feature_dim)\n",
    "        y: (output_len,)\n",
    "        \"\"\"\n",
    "        X = self.features[idx : idx + self.input_len]\n",
    "        y = self.target[idx + self.input_len : idx + self.input_len + self.output_len]\n",
    "\n",
    "        return torch.tensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수별 데이터로더 생성\n",
    "\n",
    "이 코드는 **각 예측 대상(Target) 변수별로 훈련, 검증, 테스트 데이터로더(DataLoader)를 생성하고 저장**함. 이때, **데이터의 불연속성을 처리하기 위해 각 배정번호(Batch ID) 단위로 데이터셋을 생성한 후 이를 병합**하는 방식을 사용함.\n",
    "\n",
    "  * **예측 목표 및 시퀀스 길이 설정:**\n",
    "      * `features` 리스트에는 모델이 예측할 **세 가지 목표 변수**를 정의함.\n",
    "      * `input_len = 30`은 모델 입력 시퀀스 길이를 **30**으로, `output_len = 60`은 예측 시퀀스 길이를 **60**으로 설정함.\n",
    "      * `task = 'univariate'`로 설정하여 **단변량 예측**을 수행하도록 지정함. (입력 피처로 타겟 변수 자체만 사용함)\n",
    "  * **배정번호 단위 데이터셋 생성 및 병합:**\n",
    "      * **`for target in features:`** 루프를 통해 각 타겟 변수(`'건조로 온도 2 Zone'`, `'소입2존 OP'`, `'소입로 온도 2 Zone'`)별로 다음 과정을 반복함.\n",
    "      * **배정번호별 분리:** 훈련(`train_data`), 검증(`vali_data`), 테스트(`test_data`) 각 데이터셋을 **`배정번호`의 고유 값**으로 순회함.\n",
    "      * **`TimeSeriesDataset` 생성:** 분리된 배정번호 단위의 DataFrame(`df`)을 **이전에 정의된 `TimeSeriesDataset` 클래스**를 이용해 데이터셋으로 변환함. 이는 **배정번호가 다르면 시간이 불연속적**이므로, 윈도우 슬라이딩이 배정번호 경계를 넘지 않도록 하기 위함임.\n",
    "      * **데이터셋 병합:** 각 배정번호별로 생성된 데이터셋 리스트(`trainset_list`, `valiset_list`, `testset_list`)를 `torch.utils.data.ConcatDataset`을 사용하여 **하나의 큰 데이터셋**(`trainset`, `valiset`, `testset`)으로 합침.\n",
    "  * **DataLoader 생성:**\n",
    "      * 병합된 데이터셋을 PyTorch의 `DataLoader`로 변환하여 모델 학습 시 미니배치(mini-batch)를 제공할 준비를 함.\n",
    "      * `batch_size=4096`으로 설정하여 배치 크기를 정의함.\n",
    "      * 훈련 데이터로더(`trainloader`)에만 `shuffle=True`를 적용하여 학습 시 데이터 순서를 섞음. (검증 및 테스트 데이터로더는 `shuffle=False`로 순서를 유지함.)\n",
    "  * **결과 저장:** 생성된 **훈련, 검증, 테스트 데이터로더** 튜플을 딕셔너리(`feature_dataloaders`)에 저장함. 이때 **타겟 변수명**을 딕셔너리의 키(Key)로 사용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['건조로 온도 2 Zone', '소입로 온도 4 Zone', '소입로 온도 1 Zone']\n",
    "input_len = 30\n",
    "output_len = 60\n",
    "task = 'univariate'\n",
    "feature_dataloaders = {}\n",
    "for target in features:\n",
    "    trainset_list = []\n",
    "    for id in train_data['배정번호'].unique():\n",
    "        df = train_data[train_data['배정번호']==id]\n",
    "        dataset = TimeSeriesDataset(df, input_len=input_len, output_len=output_len, target_name=target, task=task)\n",
    "        trainset_list.append(dataset)\n",
    "    trainset = torch.utils.data.ConcatDataset(trainset_list)\n",
    "\n",
    "    valiset_list = []\n",
    "    for id in vali_data['배정번호'].unique():\n",
    "        df = vali_data[vali_data['배정번호']==id]\n",
    "        dataset = TimeSeriesDataset(df, input_len=input_len, output_len=output_len, target_name=target, task=task)\n",
    "        valiset_list.append(dataset)\n",
    "    valiset = torch.utils.data.ConcatDataset(valiset_list)\n",
    "\n",
    "    testset_list = []\n",
    "    for id in test_data['배정번호'].unique():\n",
    "        df = test_data[test_data['배정번호']==id]\n",
    "        dataset = TimeSeriesDataset(df, input_len=input_len, output_len=output_len, target_name=target, task=task)\n",
    "        testset_list.append(dataset)\n",
    "    testset = torch.utils.data.ConcatDataset(testset_list)\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=4096, shuffle=True)\n",
    "    valiloader = DataLoader(valiset, batch_size=4096, shuffle=False)\n",
    "    testloader = DataLoader(testset, batch_size=4096, shuffle=False)\n",
    "    \n",
    "    feature_dataloaders[target] = (trainloader, valiloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 및 테스트 함수 정의\n",
    "\n",
    "이 코드는 **시계열 예측 모델의 학습, 검증, 최적 모델 저장, 그리고 성능 평가 및 결과 기록**을 위한 두 가지 핵심 함수(`train_model`, `test_model`)를 정의함.\n",
    "\n",
    "### **1. `train_model`의 목적 및 상세 설명**\n",
    "\n",
    "  * **목적:** 훈련 데이터셋을 사용하여 모델을 학습시키고, 검증 데이터셋에서 손실(Loss)을 모니터링하여 **최적의 성능을 보인 모델 가중치**를 저장하며, 최종적으로 해당 모델을 **ONNX 형식**으로 변환하여 저장함.\n",
    "  * **주요 기능:**\n",
    "      * **학습 루프:** `nn.MSELoss` 또는 사용자 정의 손실 함수를 기준으로 각 Epoch마다 훈련 및 검증을 수행하며 손실을 출력함.\n",
    "      * **최적 모델 저장:** 검증 손실(`val_loss`)이 **가장 낮을 때**의 모델 가중치(`state_dict`)를 `best_state`에 저장함.\n",
    "      * **ONNX 변환 및 저장:** 학습이 완료된 후, 가장 좋은 가중치를 로드하고 **`torch.onnx.export`** 함수를 사용하여 모델을 **`checkpoints/{file_name}`** 경로에 ONNX 형식으로 저장함. 이때 배치 크기를 가변적(`dynamic_axes`)으로 설정하여 범용성을 확보함.\n",
    "\n",
    "### **2. `test_model`의 목적 및 상세 설명**\n",
    "\n",
    "  * **목적:** 학습 완료된 모델을 테스트 데이터셋에 적용하여 **최종 예측 성능을 평가**하고, 그 결과를 파일에 기록함.\n",
    "  * **주요 기능:**\n",
    "      * **성능 지표 계산:** 테스트 데이터셋의 예측 결과와 실제 값(`preds_all`, `target_all`)을 사용하여 **MAE (Mean Absolute Error), RMSE (Root Mean Square Error), SMAPE (Symmetric Mean Absolute Percentage Error)** 세 가지 지표를 계산함.\n",
    "      * **결과 기록 (`result.txt`):** 계산된 성능 지표를 `result.txt` 파일에 **추가(append) 모드**로 기록함.\n",
    "      * **결과 기록 (`result.csv`):** 모델명과 성능 지표를 포함하는 행을 생성하여 **`result.csv`** 파일에 추가 기록함. (파일이 없으면 새로 생성하고, 있으면 헤더 없이 데이터만 추가함.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, valiloader, num_epochs=20, lr=1e-3, criterion=None, file_name='model.onnx'):\n",
    "    \"\"\"\n",
    "    학습 및 검증 루프\n",
    "    model: nn.Module\n",
    "    trainloader, valiloader: DataLoader\n",
    "    num_epochs: 학습 epoch 수\n",
    "    lr: learning rate\n",
    "    criterion: 손실 함수 (기본 MSE)\n",
    "    \"\"\"\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = criterion or nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ---------------- TRAIN ----------------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(X)[:,:,0]  # [batch, pred_len, n_features]\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X.size(0)\n",
    "\n",
    "        train_loss /= len(trainloader.dataset)\n",
    "\n",
    "        # ---------------- VALIDATION ----------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X, y in valiloader:\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "                preds = model(X)[:,:,0]\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "        val_loss /= len(valiloader.dataset)\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # best model 저장\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    # 학습 종료 후 best model 로드\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Best model restored (val_loss={best_val_loss:.6f})\")\n",
    "        \n",
    "    # 모델 저장\n",
    "    model.eval() # 추론 모드로 설정\n",
    "    model.cpu()\n",
    "    torch.onnx.export(\n",
    "    model,                      # 모델\n",
    "    torch.randn(1, 30, 1) ,                # 모델에 한 번 통과시킬 더미 입력 (튜플 또는 텐서)\n",
    "    f'checkpoints/{file_name}',             # 저장 경로 및 파일 이름\n",
    "    export_params=True,         # 학습된 파라미터도 함께 저장\n",
    "    opset_version=14,           # ONNX Operationset Version (일반적으로 최신 버전을 사용, 14 또는 17 권장)\n",
    "    do_constant_folding=True,   # 상수 폴딩 최적화 수행\n",
    "    input_names=['input'],      # 입력 노드 이름\n",
    "    output_names=['output'],    # 출력 노드 이름\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},   # 입력 텐서의 0번째 차원(배치)은 가변적\n",
    "        'output': {0: 'batch_size'}  # 출력 텐서의 0번째 차원(배치)은 가변적\n",
    "    }\n",
    ")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, testloader, criterion=None, file_name='model.onnx'):\n",
    "    \"\"\"\n",
    "    테스트 루프\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    criterion = criterion or nn.MSELoss()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    preds_list, target_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            preds = model(X)[:,:,0]\n",
    "            loss = criterion(preds, y)\n",
    "            test_loss += loss.item() * X.size(0)\n",
    "\n",
    "            preds_list.append(preds.cpu())\n",
    "            target_list.append(y.cpu())\n",
    "\n",
    "    preds_all = torch.cat(preds_list)\n",
    "    target_all = torch.cat(target_list)\n",
    "    \n",
    "    # 결과 출력: MAE, RMSE, SMAPE\n",
    "    mae = torch.mean(torch.abs(preds_all - target_all)).item()\n",
    "    rmse = torch.sqrt(torch.mean((preds_all - target_all) ** 2)).item()\n",
    "    smape = torch.mean(2 * torch.abs(preds_all - target_all) / (torch.abs(preds_all) + torch.abs(target_all) + 1e-8)).item() * 100\n",
    "    print(f\"[{file_name} Test Results] MAE: {mae:.6f}, RMSE: {rmse:.6f}, SMAPE: {smape:.6f}%\")\n",
    "    \n",
    "    # result.txt에 결과 추가 기록\n",
    "    with open(f'result.txt', 'a') as f:\n",
    "        f.write(f\"[{file_name} Test Results]\\n\")\n",
    "        f.write(f\"MAE: {mae:.6f}\\n\")\n",
    "        f.write(f\"RMSE: {rmse:.6f}\\n\")\n",
    "        f.write(f\"SMAPE: {smape:.6f}%\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    # result.csv에 결과 추가 기록\n",
    "    row = [file_name[:-5], mae, rmse, smape]\n",
    "    df = pd.DataFrame([row], columns=['Model', 'MAE', 'RMSE', 'SMAPE'])\n",
    "    if not os.path.isfile(f'result.csv'):\n",
    "        df.to_csv(f'result.csv', index=False)\n",
    "    else:\n",
    "        df.to_csv(f'result.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    return preds_all, target_all, (mae, rmse, smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 일괄 학습 및 테스트\n",
    "\n",
    "이 코드는 **정의된 여러 모델(`DLinear`, `NLinear`, `LSTM`)과 하이퍼파라미터 조합**을 사용하여 **모든 타겟 변수**에 대해 **모델을 일괄적으로 학습시키고 테스트를 수행**하여 최적의 조합을 탐색함. 이는 **모델 비교 실험을 자동화**하는 핵심 루프임.\n",
    "\n",
    "  * **실험 설정(`configs`):** `SimpleNamespace`를 사용하여 모델에 필요한 설정값(Configuration)을 정의함.\n",
    "      * `seq_len=30`: 입력 시퀀스 길이 30.\n",
    "      * `pred_len=60`: 예측 시퀀스 길이 60.\n",
    "      * `enc_in=1`: 입력 피처 수 1 (이전 단계에서 `task='univariate'`로 설정했으므로 단변량 입력임).\n",
    "  * **다중 루프를 통한 실험 조합 생성:** **4중 루프**를 사용하여 가능한 모든 실험 조합을 생성하고 반복함.\n",
    "    1.  **`target` (예측 대상):** 각 타겟 변수별로 실험을 수행함. (`feature_dataloaders`에서 데이터로더를 가져옴)\n",
    "    2.  **`model_name` (모델 구조):** `DLinear`, `NLinear`, `LSTM` 세 가지 모델을 순회함.\n",
    "    3.  **`learning_rate` (학습률):** `1e-3` (0.001)과 `1e-2` (0.01) 두 가지 학습률을 사용함.\n",
    "    4.  **`criterion_name` (손실 함수):** `L1Loss` (MAE)와 `MSELoss` (L2) 두 가지 손실 함수를 사용함.\n",
    "  * **모델 초기화 및 파일명 설정:**\n",
    "      * 각 루프마다 `model_dict[model_name].Model(configs)`를 호출하여 **새로운 모델**을 생성하고 GPU(`cuda()`)로 보냄.\n",
    "      * 손실 함수(`criterion`)를 설정함.\n",
    "      * `file_name`은 모델명, 타겟, 학습률, 손실 함수 이름이 포함된 고유한 이름으로 설정됨 (`DLinear_소입로 온도 2 Zone_0.001_L1Loss.onnx`와 같은 형식).\n",
    "  * **학습 및 테스트 실행:**\n",
    "      * `train_model` 함수를 호출하여 모델을 학습하고 검증 손실이 가장 낮은 모델을 ONNX 파일로 저장함.\n",
    "      * `test_model` 함수를 호출하여 학습된 모델의 최종 성능을 테스트하고, 그 결과를 `result.txt`와 `result.csv` 파일에 **누적 기록**함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] Train Loss: 0.420292 | Val Loss: 0.403872\n",
      "[Epoch 02] Train Loss: 0.362063 | Val Loss: 0.386063\n",
      "[Epoch 03] Train Loss: 0.358672 | Val Loss: 0.385080\n",
      "[Epoch 04] Train Loss: 0.357572 | Val Loss: 0.382960\n",
      "[Epoch 05] Train Loss: 0.357147 | Val Loss: 0.388940\n",
      "[Epoch 06] Train Loss: 0.356462 | Val Loss: 0.383303\n",
      "[Epoch 07] Train Loss: 0.355048 | Val Loss: 0.382110\n",
      "[Epoch 08] Train Loss: 0.354508 | Val Loss: 0.381799\n",
      "[Epoch 09] Train Loss: 0.355006 | Val Loss: 0.381396\n",
      "[Epoch 10] Train Loss: 0.354208 | Val Loss: 0.380383\n",
      "Best model restored (val_loss=0.380383)\n",
      "[DLinear_건조로 온도 2 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.357898, RMSE: 0.608660, SMAPE: 98.455328%\n",
      "[Epoch 01] Train Loss: 0.505138 | Val Loss: 0.516851\n",
      "[Epoch 02] Train Loss: 0.397197 | Val Loss: 0.459976\n",
      "[Epoch 03] Train Loss: 0.376897 | Val Loss: 0.451258\n",
      "[Epoch 04] Train Loss: 0.374099 | Val Loss: 0.441954\n",
      "[Epoch 05] Train Loss: 0.371566 | Val Loss: 0.439976\n",
      "[Epoch 06] Train Loss: 0.370147 | Val Loss: 0.444145\n",
      "[Epoch 07] Train Loss: 0.367651 | Val Loss: 0.441758\n",
      "[Epoch 08] Train Loss: 0.366897 | Val Loss: 0.448739\n",
      "[Epoch 09] Train Loss: 0.365549 | Val Loss: 0.437316\n",
      "[Epoch 10] Train Loss: 0.365803 | Val Loss: 0.444324\n",
      "Best model restored (val_loss=0.437316)\n",
      "[DLinear_건조로 온도 2 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.374610, RMSE: 0.612419, SMAPE: 96.983814%\n",
      "[Epoch 01] Train Loss: 0.713683 | Val Loss: 0.393936\n",
      "[Epoch 02] Train Loss: 0.360764 | Val Loss: 0.385813\n",
      "[Epoch 03] Train Loss: 0.356603 | Val Loss: 0.378793\n",
      "[Epoch 04] Train Loss: 0.354835 | Val Loss: 0.389272\n",
      "[Epoch 05] Train Loss: 0.355730 | Val Loss: 0.383160\n",
      "[Epoch 06] Train Loss: 0.355298 | Val Loss: 0.385660\n",
      "[Epoch 07] Train Loss: 0.355949 | Val Loss: 0.382839\n",
      "[Epoch 08] Train Loss: 0.355597 | Val Loss: 0.383967\n",
      "[Epoch 09] Train Loss: 0.355937 | Val Loss: 0.384449\n",
      "[Epoch 10] Train Loss: 0.354980 | Val Loss: 0.380301\n",
      "Best model restored (val_loss=0.378793)\n",
      "[DLinear_건조로 온도 2 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.358213, RMSE: 0.606977, SMAPE: 97.807580%\n",
      "[Epoch 01] Train Loss: 2.798278 | Val Loss: 0.512851\n",
      "[Epoch 02] Train Loss: 0.395983 | Val Loss: 0.456362\n",
      "[Epoch 03] Train Loss: 0.368601 | Val Loss: 0.436924\n",
      "[Epoch 04] Train Loss: 0.363962 | Val Loss: 0.432743\n",
      "[Epoch 05] Train Loss: 0.362361 | Val Loss: 0.436188\n",
      "[Epoch 06] Train Loss: 0.361997 | Val Loss: 0.431970\n",
      "[Epoch 07] Train Loss: 0.361339 | Val Loss: 0.435070\n",
      "[Epoch 08] Train Loss: 0.362167 | Val Loss: 0.431506\n",
      "[Epoch 09] Train Loss: 0.360567 | Val Loss: 0.433486\n",
      "[Epoch 10] Train Loss: 0.360627 | Val Loss: 0.434291\n",
      "Best model restored (val_loss=0.431506)\n",
      "[DLinear_건조로 온도 2 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.363789, RMSE: 0.598457, SMAPE: 95.400643%\n",
      "[Epoch 01] Train Loss: 0.564750 | Val Loss: 0.571123\n",
      "[Epoch 02] Train Loss: 0.514482 | Val Loss: 0.540464\n",
      "[Epoch 03] Train Loss: 0.490142 | Val Loss: 0.520428\n",
      "[Epoch 04] Train Loss: 0.473460 | Val Loss: 0.507252\n",
      "[Epoch 05] Train Loss: 0.461995 | Val Loss: 0.497792\n",
      "[Epoch 06] Train Loss: 0.454252 | Val Loss: 0.492188\n",
      "[Epoch 07] Train Loss: 0.449077 | Val Loss: 0.487915\n",
      "[Epoch 08] Train Loss: 0.445608 | Val Loss: 0.484823\n",
      "[Epoch 09] Train Loss: 0.443248 | Val Loss: 0.483414\n",
      "[Epoch 10] Train Loss: 0.441633 | Val Loss: 0.481168\n",
      "Best model restored (val_loss=0.481168)\n",
      "[NLinear_건조로 온도 2 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.404378, RMSE: 0.706797, SMAPE: 91.359770%\n",
      "[Epoch 01] Train Loss: 0.902557 | Val Loss: 0.971284\n",
      "[Epoch 02] Train Loss: 0.793822 | Val Loss: 0.890180\n",
      "[Epoch 03] Train Loss: 0.728553 | Val Loss: 0.828243\n",
      "[Epoch 04] Train Loss: 0.679273 | Val Loss: 0.779883\n",
      "[Epoch 05] Train Loss: 0.642458 | Val Loss: 0.744514\n",
      "[Epoch 06] Train Loss: 0.615381 | Val Loss: 0.718648\n",
      "[Epoch 07] Train Loss: 0.595853 | Val Loss: 0.698274\n",
      "[Epoch 08] Train Loss: 0.582079 | Val Loss: 0.684603\n",
      "[Epoch 09] Train Loss: 0.572386 | Val Loss: 0.674900\n",
      "[Epoch 10] Train Loss: 0.565719 | Val Loss: 0.668273\n",
      "Best model restored (val_loss=0.668273)\n",
      "[NLinear_건조로 온도 2 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.406722, RMSE: 0.691681, SMAPE: 91.189265%\n",
      "[Epoch 01] Train Loss: 0.482887 | Val Loss: 0.483703\n",
      "[Epoch 02] Train Loss: 0.439449 | Val Loss: 0.475773\n",
      "[Epoch 03] Train Loss: 0.436937 | Val Loss: 0.475172\n",
      "[Epoch 04] Train Loss: 0.436368 | Val Loss: 0.475563\n",
      "[Epoch 05] Train Loss: 0.436156 | Val Loss: 0.477120\n",
      "[Epoch 06] Train Loss: 0.435990 | Val Loss: 0.473400\n",
      "[Epoch 07] Train Loss: 0.435928 | Val Loss: 0.476219\n",
      "[Epoch 08] Train Loss: 0.435823 | Val Loss: 0.476684\n",
      "[Epoch 09] Train Loss: 0.435903 | Val Loss: 0.476066\n",
      "[Epoch 10] Train Loss: 0.435728 | Val Loss: 0.474047\n",
      "Best model restored (val_loss=0.473400)\n",
      "[NLinear_건조로 온도 2 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.396912, RMSE: 0.692866, SMAPE: 90.224808%\n",
      "[Epoch 01] Train Loss: 0.689253 | Val Loss: 0.666760\n",
      "[Epoch 02] Train Loss: 0.555587 | Val Loss: 0.643575\n",
      "[Epoch 03] Train Loss: 0.551293 | Val Loss: 0.647363\n",
      "[Epoch 04] Train Loss: 0.548949 | Val Loss: 0.643456\n",
      "[Epoch 05] Train Loss: 0.548213 | Val Loss: 0.643751\n",
      "[Epoch 06] Train Loss: 0.548093 | Val Loss: 0.638277\n",
      "[Epoch 07] Train Loss: 0.547617 | Val Loss: 0.644683\n",
      "[Epoch 08] Train Loss: 0.547780 | Val Loss: 0.647974\n",
      "[Epoch 09] Train Loss: 0.547422 | Val Loss: 0.641529\n",
      "[Epoch 10] Train Loss: 0.547430 | Val Loss: 0.646397\n",
      "Best model restored (val_loss=0.638277)\n",
      "[NLinear_건조로 온도 2 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.401305, RMSE: 0.680526, SMAPE: 89.854604%\n",
      "[Epoch 01] Train Loss: 0.533297 | Val Loss: 0.523753\n",
      "[Epoch 02] Train Loss: 0.417144 | Val Loss: 0.428651\n",
      "[Epoch 03] Train Loss: 0.375213 | Val Loss: 0.396007\n",
      "[Epoch 04] Train Loss: 0.360634 | Val Loss: 0.379389\n",
      "[Epoch 05] Train Loss: 0.354044 | Val Loss: 0.382374\n",
      "[Epoch 06] Train Loss: 0.350799 | Val Loss: 0.367938\n",
      "[Epoch 07] Train Loss: 0.347758 | Val Loss: 0.365590\n",
      "[Epoch 08] Train Loss: 0.345870 | Val Loss: 0.361485\n",
      "[Epoch 09] Train Loss: 0.343656 | Val Loss: 0.361068\n",
      "[Epoch 10] Train Loss: 0.342672 | Val Loss: 0.359867\n",
      "Best model restored (val_loss=0.359867)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proj03/.venv/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4279: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM_건조로 온도 2 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.347368, RMSE: 0.583053, SMAPE: 99.265420%\n",
      "[Epoch 01] Train Loss: 0.742234 | Val Loss: 0.773990\n",
      "[Epoch 02] Train Loss: 0.499409 | Val Loss: 0.518734\n",
      "[Epoch 03] Train Loss: 0.391074 | Val Loss: 0.442906\n",
      "[Epoch 04] Train Loss: 0.362365 | Val Loss: 0.412850\n",
      "[Epoch 05] Train Loss: 0.350920 | Val Loss: 0.393919\n",
      "[Epoch 06] Train Loss: 0.344095 | Val Loss: 0.389866\n",
      "[Epoch 07] Train Loss: 0.340242 | Val Loss: 0.387417\n",
      "[Epoch 08] Train Loss: 0.336201 | Val Loss: 0.377671\n",
      "[Epoch 09] Train Loss: 0.333181 | Val Loss: 0.375636\n",
      "[Epoch 10] Train Loss: 0.329712 | Val Loss: 0.374222\n",
      "Best model restored (val_loss=0.374222)\n",
      "[LSTM_건조로 온도 2 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.348209, RMSE: 0.571146, SMAPE: 96.801245%\n",
      "[Epoch 01] Train Loss: 0.436201 | Val Loss: 0.393733\n",
      "[Epoch 02] Train Loss: 0.355289 | Val Loss: 0.371477\n",
      "[Epoch 03] Train Loss: 0.345605 | Val Loss: 0.354748\n",
      "[Epoch 04] Train Loss: 0.341173 | Val Loss: 0.360853\n",
      "[Epoch 05] Train Loss: 0.339511 | Val Loss: 0.355698\n",
      "[Epoch 06] Train Loss: 0.335911 | Val Loss: 0.350436\n",
      "[Epoch 07] Train Loss: 0.335050 | Val Loss: 0.350486\n",
      "[Epoch 08] Train Loss: 0.333865 | Val Loss: 0.351732\n",
      "[Epoch 09] Train Loss: 0.334855 | Val Loss: 0.346855\n",
      "[Epoch 10] Train Loss: 0.331922 | Val Loss: 0.345166\n",
      "Best model restored (val_loss=0.345166)\n",
      "[LSTM_건조로 온도 2 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.334453, RMSE: 0.562763, SMAPE: 98.150361%\n",
      "[Epoch 01] Train Loss: 0.536725 | Val Loss: 0.465945\n",
      "[Epoch 02] Train Loss: 0.361693 | Val Loss: 0.425735\n",
      "[Epoch 03] Train Loss: 0.336293 | Val Loss: 0.378789\n",
      "[Epoch 04] Train Loss: 0.331243 | Val Loss: 0.363750\n",
      "[Epoch 05] Train Loss: 0.322883 | Val Loss: 0.383069\n",
      "[Epoch 06] Train Loss: 0.326108 | Val Loss: 0.350026\n",
      "[Epoch 07] Train Loss: 0.315169 | Val Loss: 0.351371\n",
      "[Epoch 08] Train Loss: 0.314905 | Val Loss: 0.347223\n",
      "[Epoch 09] Train Loss: 0.312728 | Val Loss: 0.341967\n",
      "[Epoch 10] Train Loss: 0.313425 | Val Loss: 0.362173\n",
      "Best model restored (val_loss=0.341967)\n",
      "[LSTM_건조로 온도 2 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.339106, RMSE: 0.563137, SMAPE: 95.176095%\n",
      "[Epoch 01] Train Loss: 0.379854 | Val Loss: 0.348548\n",
      "[Epoch 02] Train Loss: 0.361807 | Val Loss: 0.346584\n",
      "[Epoch 03] Train Loss: 0.359464 | Val Loss: 0.344671\n",
      "[Epoch 04] Train Loss: 0.358782 | Val Loss: 0.342121\n",
      "[Epoch 05] Train Loss: 0.358053 | Val Loss: 0.343694\n",
      "[Epoch 06] Train Loss: 0.358099 | Val Loss: 0.343722\n",
      "[Epoch 07] Train Loss: 0.357469 | Val Loss: 0.340653\n",
      "[Epoch 08] Train Loss: 0.357127 | Val Loss: 0.344155\n",
      "[Epoch 09] Train Loss: 0.357194 | Val Loss: 0.340892\n",
      "[Epoch 10] Train Loss: 0.356811 | Val Loss: 0.341851\n",
      "Best model restored (val_loss=0.340653)\n",
      "[DLinear_소입로 온도 4 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.323312, RMSE: 0.468889, SMAPE: 117.853367%\n",
      "[Epoch 01] Train Loss: 0.694498 | Val Loss: 0.350607\n",
      "[Epoch 02] Train Loss: 0.641704 | Val Loss: 0.340334\n",
      "[Epoch 03] Train Loss: 0.632413 | Val Loss: 0.451275\n",
      "[Epoch 04] Train Loss: 0.616456 | Val Loss: 0.362580\n",
      "[Epoch 05] Train Loss: 0.611494 | Val Loss: 0.376506\n",
      "[Epoch 06] Train Loss: 0.599129 | Val Loss: 0.317648\n",
      "[Epoch 07] Train Loss: 0.606679 | Val Loss: 0.368812\n",
      "[Epoch 08] Train Loss: 0.603437 | Val Loss: 0.324083\n",
      "[Epoch 09] Train Loss: 0.607879 | Val Loss: 0.353647\n",
      "[Epoch 10] Train Loss: 0.596701 | Val Loss: 0.345864\n",
      "Best model restored (val_loss=0.317648)\n",
      "[DLinear_소입로 온도 4 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.365583, RMSE: 0.540564, SMAPE: 123.660243%\n",
      "[Epoch 01] Train Loss: 0.562233 | Val Loss: 0.345715\n",
      "[Epoch 02] Train Loss: 0.359349 | Val Loss: 0.346534\n",
      "[Epoch 03] Train Loss: 0.358201 | Val Loss: 0.350462\n",
      "[Epoch 04] Train Loss: 0.357731 | Val Loss: 0.341620\n",
      "[Epoch 05] Train Loss: 0.356936 | Val Loss: 0.341825\n",
      "[Epoch 06] Train Loss: 0.356757 | Val Loss: 0.344457\n",
      "[Epoch 07] Train Loss: 0.357129 | Val Loss: 0.343261\n",
      "[Epoch 08] Train Loss: 0.357022 | Val Loss: 0.342026\n",
      "[Epoch 09] Train Loss: 0.356625 | Val Loss: 0.342165\n",
      "[Epoch 10] Train Loss: 0.357809 | Val Loss: 0.341182\n",
      "Best model restored (val_loss=0.341182)\n",
      "[DLinear_소입로 온도 4 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.323886, RMSE: 0.467842, SMAPE: 118.626463%\n",
      "[Epoch 01] Train Loss: 1.622746 | Val Loss: 0.546995\n",
      "[Epoch 02] Train Loss: 0.641517 | Val Loss: 0.334600\n",
      "[Epoch 03] Train Loss: 0.635597 | Val Loss: 0.295297\n",
      "[Epoch 04] Train Loss: 0.621016 | Val Loss: 0.504718\n",
      "[Epoch 05] Train Loss: 0.605215 | Val Loss: 0.388270\n",
      "[Epoch 06] Train Loss: 0.592929 | Val Loss: 0.336389\n",
      "[Epoch 07] Train Loss: 0.607277 | Val Loss: 0.484189\n",
      "[Epoch 08] Train Loss: 0.609540 | Val Loss: 0.388692\n",
      "[Epoch 09] Train Loss: 0.601203 | Val Loss: 0.321418\n",
      "[Epoch 10] Train Loss: 0.601166 | Val Loss: 0.358295\n",
      "Best model restored (val_loss=0.295297)\n",
      "[DLinear_소입로 온도 4 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.371684, RMSE: 0.549816, SMAPE: 122.090876%\n",
      "[Epoch 01] Train Loss: 0.581575 | Val Loss: 0.566070\n",
      "[Epoch 02] Train Loss: 0.534945 | Val Loss: 0.542008\n",
      "[Epoch 03] Train Loss: 0.524094 | Val Loss: 0.532526\n",
      "[Epoch 04] Train Loss: 0.519022 | Val Loss: 0.527207\n",
      "[Epoch 05] Train Loss: 0.515982 | Val Loss: 0.524064\n",
      "[Epoch 06] Train Loss: 0.513854 | Val Loss: 0.521702\n",
      "[Epoch 07] Train Loss: 0.512231 | Val Loss: 0.519841\n",
      "[Epoch 08] Train Loss: 0.510922 | Val Loss: 0.518406\n",
      "[Epoch 09] Train Loss: 0.509856 | Val Loss: 0.517294\n",
      "[Epoch 10] Train Loss: 0.508991 | Val Loss: 0.516199\n",
      "Best model restored (val_loss=0.516199)\n",
      "[NLinear_소입로 온도 4 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.465078, RMSE: 0.694121, SMAPE: 126.425886%\n",
      "[Epoch 01] Train Loss: 0.874692 | Val Loss: 0.716349\n",
      "[Epoch 02] Train Loss: 0.778736 | Val Loss: 0.660277\n",
      "[Epoch 03] Train Loss: 0.755258 | Val Loss: 0.634956\n",
      "[Epoch 04] Train Loss: 0.743763 | Val Loss: 0.621991\n",
      "[Epoch 05] Train Loss: 0.737048 | Val Loss: 0.609924\n",
      "[Epoch 06] Train Loss: 0.732680 | Val Loss: 0.606955\n",
      "[Epoch 07] Train Loss: 0.728997 | Val Loss: 0.602532\n",
      "[Epoch 08] Train Loss: 0.725706 | Val Loss: 0.602781\n",
      "[Epoch 09] Train Loss: 0.723110 | Val Loss: 0.597267\n",
      "[Epoch 10] Train Loss: 0.720738 | Val Loss: 0.596853\n",
      "Best model restored (val_loss=0.596853)\n",
      "[NLinear_소입로 온도 4 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.468356, RMSE: 0.701158, SMAPE: 125.669503%\n",
      "[Epoch 01] Train Loss: 0.524218 | Val Loss: 0.515957\n",
      "[Epoch 02] Train Loss: 0.506540 | Val Loss: 0.510834\n",
      "[Epoch 03] Train Loss: 0.504791 | Val Loss: 0.508469\n",
      "[Epoch 04] Train Loss: 0.503746 | Val Loss: 0.507514\n",
      "[Epoch 05] Train Loss: 0.503195 | Val Loss: 0.506763\n",
      "[Epoch 06] Train Loss: 0.502782 | Val Loss: 0.507829\n",
      "[Epoch 07] Train Loss: 0.502506 | Val Loss: 0.506166\n",
      "[Epoch 08] Train Loss: 0.502255 | Val Loss: 0.506993\n",
      "[Epoch 09] Train Loss: 0.501991 | Val Loss: 0.505761\n",
      "[Epoch 10] Train Loss: 0.501821 | Val Loss: 0.506410\n",
      "Best model restored (val_loss=0.505761)\n",
      "[NLinear_소입로 온도 4 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.458515, RMSE: 0.680339, SMAPE: 126.090217%\n",
      "[Epoch 01] Train Loss: 0.766123 | Val Loss: 0.602846\n",
      "[Epoch 02] Train Loss: 0.719047 | Val Loss: 0.579868\n",
      "[Epoch 03] Train Loss: 0.709212 | Val Loss: 0.571992\n",
      "[Epoch 04] Train Loss: 0.703694 | Val Loss: 0.563763\n",
      "[Epoch 05] Train Loss: 0.702929 | Val Loss: 0.581176\n",
      "[Epoch 06] Train Loss: 0.700823 | Val Loss: 0.562932\n",
      "[Epoch 07] Train Loss: 0.700570 | Val Loss: 0.566549\n",
      "[Epoch 08] Train Loss: 0.697883 | Val Loss: 0.562080\n",
      "[Epoch 09] Train Loss: 0.697901 | Val Loss: 0.574788\n",
      "[Epoch 10] Train Loss: 0.698270 | Val Loss: 0.556606\n",
      "Best model restored (val_loss=0.556606)\n",
      "[NLinear_소입로 온도 4 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.461188, RMSE: 0.681570, SMAPE: 125.844121%\n",
      "[Epoch 01] Train Loss: 0.439306 | Val Loss: 0.401307\n",
      "[Epoch 02] Train Loss: 0.386187 | Val Loss: 0.352665\n",
      "[Epoch 03] Train Loss: 0.364723 | Val Loss: 0.345371\n",
      "[Epoch 04] Train Loss: 0.359515 | Val Loss: 0.344243\n",
      "[Epoch 05] Train Loss: 0.356617 | Val Loss: 0.339525\n",
      "[Epoch 06] Train Loss: 0.353339 | Val Loss: 0.340319\n",
      "[Epoch 07] Train Loss: 0.351286 | Val Loss: 0.337851\n",
      "[Epoch 08] Train Loss: 0.349438 | Val Loss: 0.339554\n",
      "[Epoch 09] Train Loss: 0.347697 | Val Loss: 0.334912\n",
      "[Epoch 10] Train Loss: 0.346195 | Val Loss: 0.335339\n",
      "Best model restored (val_loss=0.334912)\n",
      "[LSTM_소입로 온도 4 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.316480, RMSE: 0.461968, SMAPE: 117.784142%\n",
      "[Epoch 01] Train Loss: 0.806121 | Val Loss: 0.298494\n",
      "[Epoch 02] Train Loss: 0.678152 | Val Loss: 0.260014\n",
      "[Epoch 03] Train Loss: 0.621442 | Val Loss: 0.262222\n",
      "[Epoch 04] Train Loss: 0.581025 | Val Loss: 0.249483\n",
      "[Epoch 05] Train Loss: 0.546099 | Val Loss: 0.243232\n",
      "[Epoch 06] Train Loss: 0.513241 | Val Loss: 0.245215\n",
      "[Epoch 07] Train Loss: 0.484698 | Val Loss: 0.242388\n",
      "[Epoch 08] Train Loss: 0.458161 | Val Loss: 0.242590\n",
      "[Epoch 09] Train Loss: 0.435010 | Val Loss: 0.242343\n",
      "[Epoch 10] Train Loss: 0.415327 | Val Loss: 0.237541\n",
      "Best model restored (val_loss=0.237541)\n",
      "[LSTM_소입로 온도 4 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.324672, RMSE: 0.467302, SMAPE: 117.114818%\n",
      "[Epoch 01] Train Loss: 0.400917 | Val Loss: 0.358436\n",
      "[Epoch 02] Train Loss: 0.360809 | Val Loss: 0.342030\n",
      "[Epoch 03] Train Loss: 0.352840 | Val Loss: 0.338677\n",
      "[Epoch 04] Train Loss: 0.346963 | Val Loss: 0.340592\n",
      "[Epoch 05] Train Loss: 0.343546 | Val Loss: 0.337519\n",
      "[Epoch 06] Train Loss: 0.341652 | Val Loss: 0.334947\n",
      "[Epoch 07] Train Loss: 0.340838 | Val Loss: 0.330854\n",
      "[Epoch 08] Train Loss: 0.339620 | Val Loss: 0.330723\n",
      "[Epoch 09] Train Loss: 0.338480 | Val Loss: 0.329678\n",
      "[Epoch 10] Train Loss: 0.337695 | Val Loss: 0.330766\n",
      "Best model restored (val_loss=0.329678)\n",
      "[LSTM_소입로 온도 4 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.311645, RMSE: 0.455928, SMAPE: 115.969825%\n",
      "[Epoch 01] Train Loss: 0.668678 | Val Loss: 0.274233\n",
      "[Epoch 02] Train Loss: 0.439117 | Val Loss: 0.257503\n",
      "[Epoch 03] Train Loss: 0.340382 | Val Loss: 0.236536\n",
      "[Epoch 04] Train Loss: 0.329744 | Val Loss: 0.240989\n",
      "[Epoch 05] Train Loss: 0.316904 | Val Loss: 0.235197\n",
      "[Epoch 06] Train Loss: 0.288489 | Val Loss: 0.232360\n",
      "[Epoch 07] Train Loss: 0.281033 | Val Loss: 0.236049\n",
      "[Epoch 08] Train Loss: 0.275525 | Val Loss: 0.236384\n",
      "[Epoch 09] Train Loss: 0.276547 | Val Loss: 0.237532\n",
      "[Epoch 10] Train Loss: 0.268333 | Val Loss: 0.229272\n",
      "Best model restored (val_loss=0.229272)\n",
      "[LSTM_소입로 온도 4 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.318934, RMSE: 0.459654, SMAPE: 115.166998%\n",
      "[Epoch 01] Train Loss: 0.522854 | Val Loss: 0.574106\n",
      "[Epoch 02] Train Loss: 0.489825 | Val Loss: 0.565009\n",
      "[Epoch 03] Train Loss: 0.483007 | Val Loss: 0.558277\n",
      "[Epoch 04] Train Loss: 0.478400 | Val Loss: 0.553956\n",
      "[Epoch 05] Train Loss: 0.475607 | Val Loss: 0.549096\n",
      "[Epoch 06] Train Loss: 0.471895 | Val Loss: 0.547732\n",
      "[Epoch 07] Train Loss: 0.470325 | Val Loss: 0.545510\n",
      "[Epoch 08] Train Loss: 0.469149 | Val Loss: 0.545447\n",
      "[Epoch 09] Train Loss: 0.467244 | Val Loss: 0.540781\n",
      "[Epoch 10] Train Loss: 0.466981 | Val Loss: 0.547862\n",
      "Best model restored (val_loss=0.540781)\n",
      "[DLinear_소입로 온도 1 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.432799, RMSE: 0.797806, SMAPE: 94.906372%\n",
      "[Epoch 01] Train Loss: 0.750298 | Val Loss: 0.910577\n",
      "[Epoch 02] Train Loss: 0.678804 | Val Loss: 0.876167\n",
      "[Epoch 03] Train Loss: 0.668441 | Val Loss: 0.873475\n",
      "[Epoch 04] Train Loss: 0.659571 | Val Loss: 0.861795\n",
      "[Epoch 05] Train Loss: 0.653670 | Val Loss: 0.851151\n",
      "[Epoch 06] Train Loss: 0.649526 | Val Loss: 0.851510\n",
      "[Epoch 07] Train Loss: 0.646442 | Val Loss: 0.848612\n",
      "[Epoch 08] Train Loss: 0.644208 | Val Loss: 0.847854\n",
      "[Epoch 09] Train Loss: 0.640919 | Val Loss: 0.843854\n",
      "[Epoch 10] Train Loss: 0.639551 | Val Loss: 0.846250\n",
      "Best model restored (val_loss=0.843854)\n",
      "[DLinear_소입로 온도 1 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.449802, RMSE: 0.780730, SMAPE: 118.140125%\n",
      "[Epoch 01] Train Loss: 0.823032 | Val Loss: 0.568949\n",
      "[Epoch 02] Train Loss: 0.476669 | Val Loss: 0.543920\n",
      "[Epoch 03] Train Loss: 0.468976 | Val Loss: 0.543927\n",
      "[Epoch 04] Train Loss: 0.466622 | Val Loss: 0.543748\n",
      "[Epoch 05] Train Loss: 0.463523 | Val Loss: 0.549228\n",
      "[Epoch 06] Train Loss: 0.464384 | Val Loss: 0.535031\n",
      "[Epoch 07] Train Loss: 0.464499 | Val Loss: 0.545007\n",
      "[Epoch 08] Train Loss: 0.461883 | Val Loss: 0.532397\n",
      "[Epoch 09] Train Loss: 0.458335 | Val Loss: 0.530347\n",
      "[Epoch 10] Train Loss: 0.459026 | Val Loss: 0.539782\n",
      "Best model restored (val_loss=0.530347)\n",
      "[DLinear_소입로 온도 1 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.426064, RMSE: 0.780498, SMAPE: 95.078671%\n",
      "[Epoch 01] Train Loss: 3.662315 | Val Loss: 1.029149\n",
      "[Epoch 02] Train Loss: 0.669099 | Val Loss: 0.854745\n",
      "[Epoch 03] Train Loss: 0.642468 | Val Loss: 0.838944\n",
      "[Epoch 04] Train Loss: 0.636596 | Val Loss: 0.835703\n",
      "[Epoch 05] Train Loss: 0.632165 | Val Loss: 0.831090\n",
      "[Epoch 06] Train Loss: 0.629207 | Val Loss: 0.825083\n",
      "[Epoch 07] Train Loss: 0.626878 | Val Loss: 0.824829\n",
      "[Epoch 08] Train Loss: 0.624930 | Val Loss: 0.823382\n",
      "[Epoch 09] Train Loss: 0.623512 | Val Loss: 0.816098\n",
      "[Epoch 10] Train Loss: 0.622241 | Val Loss: 0.819761\n",
      "Best model restored (val_loss=0.816098)\n",
      "[DLinear_소입로 온도 1 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.439970, RMSE: 0.767020, SMAPE: 113.905656%\n",
      "[Epoch 01] Train Loss: 0.661503 | Val Loss: 0.732864\n",
      "[Epoch 02] Train Loss: 0.609528 | Val Loss: 0.705186\n",
      "[Epoch 03] Train Loss: 0.594462 | Val Loss: 0.693818\n",
      "[Epoch 04] Train Loss: 0.588219 | Val Loss: 0.688313\n",
      "[Epoch 05] Train Loss: 0.584549 | Val Loss: 0.684687\n",
      "[Epoch 06] Train Loss: 0.581834 | Val Loss: 0.681814\n",
      "[Epoch 07] Train Loss: 0.579598 | Val Loss: 0.680072\n",
      "[Epoch 08] Train Loss: 0.577635 | Val Loss: 0.678132\n",
      "[Epoch 09] Train Loss: 0.575915 | Val Loss: 0.675766\n",
      "[Epoch 10] Train Loss: 0.574311 | Val Loss: 0.673373\n",
      "Best model restored (val_loss=0.673373)\n",
      "[NLinear_소입로 온도 1 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.537590, RMSE: 0.983869, SMAPE: 96.693271%\n",
      "[Epoch 01] Train Loss: 1.177865 | Val Loss: 1.431937\n",
      "[Epoch 02] Train Loss: 1.062619 | Val Loss: 1.365089\n",
      "[Epoch 03] Train Loss: 1.031690 | Val Loss: 1.339748\n",
      "[Epoch 04] Train Loss: 1.019084 | Val Loss: 1.326376\n",
      "[Epoch 05] Train Loss: 1.012151 | Val Loss: 1.319195\n",
      "[Epoch 06] Train Loss: 1.007114 | Val Loss: 1.313237\n",
      "[Epoch 07] Train Loss: 1.003022 | Val Loss: 1.303903\n",
      "[Epoch 08] Train Loss: 0.999174 | Val Loss: 1.296673\n",
      "[Epoch 09] Train Loss: 0.995673 | Val Loss: 1.295267\n",
      "[Epoch 10] Train Loss: 0.992425 | Val Loss: 1.289945\n",
      "Best model restored (val_loss=1.289945)\n",
      "[NLinear_소입로 온도 1 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.539771, RMSE: 0.973649, SMAPE: 97.838438%\n",
      "[Epoch 01] Train Loss: 0.601089 | Val Loss: 0.675290\n",
      "[Epoch 02] Train Loss: 0.570802 | Val Loss: 0.666271\n",
      "[Epoch 03] Train Loss: 0.563543 | Val Loss: 0.660158\n",
      "[Epoch 04] Train Loss: 0.559374 | Val Loss: 0.654119\n",
      "[Epoch 05] Train Loss: 0.556677 | Val Loss: 0.651243\n",
      "[Epoch 06] Train Loss: 0.555167 | Val Loss: 0.652504\n",
      "[Epoch 07] Train Loss: 0.553712 | Val Loss: 0.650784\n",
      "[Epoch 08] Train Loss: 0.552710 | Val Loss: 0.648718\n",
      "[Epoch 09] Train Loss: 0.551820 | Val Loss: 0.644906\n",
      "[Epoch 10] Train Loss: 0.551178 | Val Loss: 0.650728\n",
      "Best model restored (val_loss=0.644906)\n",
      "[NLinear_소입로 온도 1 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.518456, RMSE: 0.961317, SMAPE: 94.446170%\n",
      "[Epoch 01] Train Loss: 1.046222 | Val Loss: 1.301149\n",
      "[Epoch 02] Train Loss: 0.984174 | Val Loss: 1.281202\n",
      "[Epoch 03] Train Loss: 0.967801 | Val Loss: 1.250069\n",
      "[Epoch 04] Train Loss: 0.955697 | Val Loss: 1.249686\n",
      "[Epoch 05] Train Loss: 0.948063 | Val Loss: 1.237263\n",
      "[Epoch 06] Train Loss: 0.941900 | Val Loss: 1.229922\n",
      "[Epoch 07] Train Loss: 0.937597 | Val Loss: 1.234846\n",
      "[Epoch 08] Train Loss: 0.934665 | Val Loss: 1.222805\n",
      "[Epoch 09] Train Loss: 0.932413 | Val Loss: 1.219998\n",
      "[Epoch 10] Train Loss: 0.930703 | Val Loss: 1.244449\n",
      "Best model restored (val_loss=1.219998)\n",
      "[NLinear_소입로 온도 1 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.518757, RMSE: 0.948996, SMAPE: 95.836401%\n",
      "[Epoch 01] Train Loss: 0.586287 | Val Loss: 0.639191\n",
      "[Epoch 02] Train Loss: 0.467590 | Val Loss: 0.491960\n",
      "[Epoch 03] Train Loss: 0.408425 | Val Loss: 0.462649\n",
      "[Epoch 04] Train Loss: 0.392851 | Val Loss: 0.445689\n",
      "[Epoch 05] Train Loss: 0.383490 | Val Loss: 0.440279\n",
      "[Epoch 06] Train Loss: 0.377606 | Val Loss: 0.430626\n",
      "[Epoch 07] Train Loss: 0.372851 | Val Loss: 0.429560\n",
      "[Epoch 08] Train Loss: 0.369470 | Val Loss: 0.427082\n",
      "[Epoch 09] Train Loss: 0.366135 | Val Loss: 0.420275\n",
      "[Epoch 10] Train Loss: 0.364052 | Val Loss: 0.419323\n",
      "Best model restored (val_loss=0.419323)\n",
      "[LSTM_소입로 온도 1 Zone_0.001_L1Loss.onnx Test Results] MAE: 0.341813, RMSE: 0.689611, SMAPE: 78.861636%\n",
      "[Epoch 01] Train Loss: 0.907914 | Val Loss: 1.012099\n",
      "[Epoch 02] Train Loss: 0.607602 | Val Loss: 0.718971\n",
      "[Epoch 03] Train Loss: 0.516936 | Val Loss: 0.672307\n",
      "[Epoch 04] Train Loss: 0.493555 | Val Loss: 0.658528\n",
      "[Epoch 05] Train Loss: 0.481210 | Val Loss: 0.640975\n",
      "[Epoch 06] Train Loss: 0.471970 | Val Loss: 0.632210\n",
      "[Epoch 07] Train Loss: 0.466878 | Val Loss: 0.624481\n",
      "[Epoch 08] Train Loss: 0.459448 | Val Loss: 0.614188\n",
      "[Epoch 09] Train Loss: 0.455619 | Val Loss: 0.612197\n",
      "[Epoch 10] Train Loss: 0.451816 | Val Loss: 0.604215\n",
      "Best model restored (val_loss=0.604215)\n",
      "[LSTM_소입로 온도 1 Zone_0.001_MSELoss.onnx Test Results] MAE: 0.370565, RMSE: 0.677992, SMAPE: 84.111100%\n",
      "[Epoch 01] Train Loss: 0.477443 | Val Loss: 0.465196\n",
      "[Epoch 02] Train Loss: 0.385343 | Val Loss: 0.439748\n",
      "[Epoch 03] Train Loss: 0.369149 | Val Loss: 0.412159\n",
      "[Epoch 04] Train Loss: 0.360596 | Val Loss: 0.410536\n",
      "[Epoch 05] Train Loss: 0.355403 | Val Loss: 0.403959\n",
      "[Epoch 06] Train Loss: 0.352202 | Val Loss: 0.402355\n",
      "[Epoch 07] Train Loss: 0.347145 | Val Loss: 0.401601\n",
      "[Epoch 08] Train Loss: 0.345213 | Val Loss: 0.399173\n",
      "[Epoch 09] Train Loss: 0.342680 | Val Loss: 0.400062\n",
      "[Epoch 10] Train Loss: 0.340374 | Val Loss: 0.396367\n",
      "Best model restored (val_loss=0.396367)\n",
      "[LSTM_소입로 온도 1 Zone_0.01_L1Loss.onnx Test Results] MAE: 0.324851, RMSE: 0.669394, SMAPE: 74.930692%\n",
      "[Epoch 01] Train Loss: 0.618317 | Val Loss: 0.649950\n",
      "[Epoch 02] Train Loss: 0.478529 | Val Loss: 0.619619\n",
      "[Epoch 03] Train Loss: 0.454259 | Val Loss: 0.603127\n",
      "[Epoch 04] Train Loss: 0.441582 | Val Loss: 0.585726\n",
      "[Epoch 05] Train Loss: 0.433474 | Val Loss: 0.605544\n",
      "[Epoch 06] Train Loss: 0.431223 | Val Loss: 0.593996\n",
      "[Epoch 07] Train Loss: 0.426449 | Val Loss: 0.580458\n",
      "[Epoch 08] Train Loss: 0.415765 | Val Loss: 0.573637\n",
      "[Epoch 09] Train Loss: 0.414576 | Val Loss: 0.560548\n",
      "[Epoch 10] Train Loss: 0.411281 | Val Loss: 0.560466\n",
      "Best model restored (val_loss=0.560466)\n",
      "[LSTM_소입로 온도 1 Zone_0.01_MSELoss.onnx Test Results] MAE: 0.344029, RMSE: 0.651624, SMAPE: 79.327822%\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'DLinear': DLinear,\n",
    "    'NLinear': NLinear,\n",
    "    'LSTM': LSTM,\n",
    "}\n",
    "\n",
    "configs = SimpleNamespace(\n",
    "    seq_len=30,\n",
    "    pred_len=60,\n",
    "    moving_avg=25,\n",
    "    individual=False,\n",
    "    enc_in=1, # feature 수: 1 or 18\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "for target in features:\n",
    "    trainloader, valiloader, testloader = feature_dataloaders[target]\n",
    "    for model_name in model_dict.keys():\n",
    "        for learning_rate in [1e-3, 1e-2]:\n",
    "            for criterion_name in ['L1Loss', 'MSELoss']:\n",
    "                model = model_dict[model_name].Model(configs).float().cuda()\n",
    "                if criterion_name == 'MSELoss':\n",
    "                    criterion = nn.MSELoss()\n",
    "                else:\n",
    "                    criterion = nn.L1Loss()\n",
    "                file_name = f'{model_name}_{target}_{learning_rate}_{criterion_name}.onnx'\n",
    "\n",
    "                # 학습 및 검증\n",
    "                trained_model = train_model(model, trainloader, valiloader, num_epochs=10, lr=learning_rate, criterion=criterion, file_name=file_name)\n",
    "\n",
    "                # 테스트\n",
    "                preds, targets, test_loss = test_model(trained_model, testloader, criterion, file_name=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최고 성능 모델 확인\n",
    "\n",
    "이 코드는 **실험 결과 파일(`result.csv`)을 읽어와서 모든 모델의 성능을 비교**하고, **각 타겟 변수별로 가장 좋은 성능 지표(MAE 기준)를 달성한 최적 모델 조합을 식별하고 정리**함.\n",
    "\n",
    "  * **결과 데이터 로드:** `pd.read_csv('result.csv', index_col='Model')`을 사용하여 이전에 `test_model` 함수에서 누적 기록한 **모든 실험 결과**를 DataFrame으로 불러옴.\n",
    "  * **인덱스 분해:** 이전 단계와 동일하게, 복합적인 인덱스(예: `LSTM_소입로 온도 2 Zone_0.001_L1Loss`)를 **`model`, `target`, `learning_rate`, `loss_type`** 네 가지 개별 컬럼으로 정확하게 분리함. 이는 각 하이퍼파라미터 조합별로 비교하기 위함임.\n",
    "  * **최적 모델 선택 (MAE 기준):** `result_df.groupby('target')['MAE'].idxmin()`을 사용하여 각 타겟 변수 그룹 내에서 **가장 낮은 MAE 값**을 가진 행을 찾아냄. 낮은 MAE는 모델의 오차가 적다는 것을 의미하므로, **가장 좋은 성능**을 나타내는 기준으로 사용됨.\n",
    "  * **최종 결과 정리 및 출력:**\n",
    "      * 선택된 최적 모델들의 정보(`model`, `target`, `learning_rate`, `loss_type`, `MAE`, `RMSE`, `SMAPE`)만 `final_best_df`로 정리함.\n",
    "      * 이 DataFrame을 Markdown 형식의 표로 출력하여 사용자가 **타겟별 최고 성능 모델**을 한눈에 확인할 수 있게 함.\n",
    "  * **최적 ONNX 파일명 저장:**\n",
    "      * `for target in features:` 루프를 통해 각 타겟별 최적 모델 행을 가져옴.\n",
    "      * **모델, 타겟, 학습률, 손실 타입**을 언더바(`_`)로 다시 연결하고 `.onnx`를 붙여 **최고 성능 모델의 ONNX 파일명**을 생성함.\n",
    "      * 이 파일명을 **`best_models` 딕셔너리**에 저장하여, 이후 시뮬레이션이나 실제 배포 시 어떤 파일(`*.onnx`)을 사용해야 하는지 명확히 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟별 최적 조합 결과 (MAE 기준):\n",
      "\n",
      "| model   | target             |   learning_rate | loss_type   |      MAE |     RMSE |    SMAPE |\n",
      "|:--------|:-------------------|----------------:|:------------|---------:|---------:|---------:|\n",
      "| LSTM    | 건조로 온도 2 Zone |            0.01 | L1Loss      | 0.334453 | 0.562763 |  98.1504 |\n",
      "| LSTM    | 소입로 온도 1 Zone |            0.01 | L1Loss      | 0.324851 | 0.669394 |  74.9307 |\n",
      "| LSTM    | 소입로 온도 4 Zone |            0.01 | L1Loss      | 0.311645 | 0.455928 | 115.97   |\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.read_csv('result.csv', index_col='Model')\n",
    "\n",
    "# 2. 인덱스(Model) 분할 및 새 컬럼 생성\n",
    "model_parts = result_df.index.str.split('_', expand=True)\n",
    "\n",
    "result_df['model'] = model_parts.get_level_values(0)\n",
    "\n",
    "split_df = result_df.index.to_series().apply(lambda x: x.rsplit('_', 3))\n",
    "result_df['model'] = split_df.apply(lambda x: x[0])\n",
    "result_df['target'] = split_df.apply(lambda x: x[1].replace(' ', '_')) # Target에 띄어쓰기가 있다면 임시로 _로 변경\n",
    "result_df['learning_rate'] = split_df.apply(lambda x: x[2])\n",
    "result_df['loss_type'] = split_df.apply(lambda x: x[3])\n",
    "\n",
    "# target 컬럼의 띄어쓰기를 원래대로 복구\n",
    "result_df['target'] = result_df['target'].str.replace('_', ' ')\n",
    "\n",
    "# 3. 각 Target 별로 MAE가 가장 낮은 행 선택\n",
    "best_results_per_target = result_df.loc[result_df.groupby('target')['MAE'].idxmin()]\n",
    "\n",
    "# 4. 최종 출력 컬럼 정리\n",
    "output_columns = ['model', 'target', 'learning_rate', 'loss_type', 'MAE', 'RMSE', 'SMAPE']\n",
    "final_best_df = best_results_per_target[output_columns].reset_index(drop=True)\n",
    "\n",
    "best_models = {}\n",
    "for target in features:\n",
    "    model_row = final_best_df[final_best_df['target']==target].iloc[:,0:4]\n",
    "    concatenated_name = '_'.join(model_row.values[0])\n",
    "    best_model = concatenated_name + '.onnx'\n",
    "    best_models[target] = best_model\n",
    "\n",
    "print(\"타겟별 최적 조합 결과 (MAE 기준):\\n\")\n",
    "print(final_best_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}